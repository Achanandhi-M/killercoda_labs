## Welcome to the Ollama Playground Lab

You now have a clean Ubuntu environment with **Ollama already installed and running** for you.
In this task, you will **run an open-source LLM locally**—just like interacting with ChatGPT, but fully on your own machine.

Follow the steps below

---

## Step 1: Pull & Run the Gemma 3 (270M) Model

Ollama makes it super easy to pull and run models.
To launch the **Gemma 3 – 270M** model, just run:

```
ollama run gemma3:270m
```

---

## Step 2: Start Chatting With the Model

As soon as you run the above command:

* Ollama will download the model (only the first time)
* The model will start
* You can chat with it like this:

Example:

```
>>> Hello!
Hello! How can I help you today?
```

Feel free to ask anything—just like you would ask ChatGPT.

---

## Step 3: Try Your Own Prompts

Here are some ideas you can try:

* “Explain Docker in simple words.”
* “Write a small Python script to reverse a string.”
* “Summarize this sentence…”
* “Give me 5 fun facts about AI.”

The goal is to **experience how fast and local LLMs work**.

---

## That's It!

You’ve successfully:

* Started the Ollama server
* Pulled the Gemma3 model
* Interacted with a local LLM
